{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phi.tf.flow import * \n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.signal import convolve\n",
    "from phi.tf.flow import *\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import concurrent.futures\n",
    "\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import json\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, simulation_path, k):\n",
    "        self.simulation_path = simulation_path\n",
    "        self.k = k\n",
    "        self.num_simulations, self.num_timesteps = self._count_simulations_and_timesteps()\n",
    "        self.data = self._load_velocity_data()\n",
    "        self.batched_data = None\n",
    "        self.batched_std = None\n",
    "        \n",
    "\n",
    "    def _count_simulations_and_timesteps(self):\n",
    "        # Count the number of simulation directories\n",
    "        simulation_dirs = [d for d in os.listdir(self.simulation_path) if os.path.isdir(os.path.join(self.simulation_path, d))]\n",
    "        num_simulations = len(simulation_dirs)\n",
    "\n",
    "        # Count the number of velocity files in the first simulation directory\n",
    "        first_sim_dir = os.path.join(self.simulation_path, simulation_dirs[0])\n",
    "        velocity_files = [f for f in os.listdir(first_sim_dir) if f.startswith('velocity') and f.endswith('.npz')]\n",
    "        num_timesteps = len(velocity_files)\n",
    "        print(f\"Number of simulations: {num_simulations}, Number of timesteps: {num_timesteps}\")\n",
    "        return num_simulations, num_timesteps\n",
    "    \n",
    "\n",
    "    def _load_velocity_data(self):\n",
    "            def load_data_with_progress(sim):\n",
    "                result = self._load_simulation_data(sim)\n",
    "                progress = (sim + 1) / self.num_simulations * 100  # Calculate progress\n",
    "                print(f\"Progress: {progress:.2f}%\")\n",
    "                return result\n",
    "\n",
    "            with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "                data = list(executor.map(load_data_with_progress, range(self.num_simulations)))\n",
    "            # Filter out empty arrays from each array in data before flattening\n",
    "            return [element for array in data if array for element in array]                \n",
    "\n",
    "    def _load_simulation_data(self, sim):\n",
    "\n",
    "        sim_dir = os.path.join(self.simulation_path, f'sim_{sim:06d}')\n",
    "        print(f\"Loading simulation {sim + 1}/{self.num_simulations}\")\n",
    "\n",
    "        if not os.path.exists(sim_dir):\n",
    "            print(f\"Simulation directory {sim_dir} not found, skipping to the next simulation.\")\n",
    "            return []  # Return empty list for missing simulations\n",
    "        sim_data = []\n",
    "        for t in range(self.num_timesteps):\n",
    "            try:\n",
    "                velocity_data = np.load(os.path.join(sim_dir, f'velocity_{(t):06d}.npz'))['data']\n",
    "                advection_diffusion_data = np.load(os.path.join(sim_dir, f'advection_diffusion_sum_{(t):06d}.npz'))['data']\n",
    "\n",
    "\n",
    "                sim_data.append((velocity_data, advection_diffusion_data))\n",
    "    \n",
    "\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File not found for simulation {sim}, timestep {t}, skipping to the next timestep.\")\n",
    "\n",
    "\n",
    "        print(f\"Loaded simulation {sim + 1}/{self.num_simulations}\")\n",
    "        return sim_data\n",
    "    \n",
    "    def _compute_batch_std(self, batch_data):\n",
    "\n",
    "        velocity_data_list = []\n",
    "        advection_diffusion_data_list = []\n",
    "\n",
    "        for sim, velocity_data, advection_diffusion_data, _ , _ in batch_data:\n",
    "            velocity_data_list.append(velocity_data)\n",
    "            advection_diffusion_data_list.append(advection_diffusion_data)\n",
    "\n",
    "        # Convert lists to numpy arrays\n",
    "        velocity_data_array = np.array(velocity_data_list)\n",
    "        advection_diffusion_data_array = np.array(advection_diffusion_data_list)\n",
    "\n",
    "\n",
    "        velocity_std = np.std(velocity_data_array.flatten())\n",
    "        advection_diffusion_std = np.std(advection_diffusion_data_array.flatten())\n",
    "\n",
    "        return velocity_std, advection_diffusion_std\n",
    "    def prepare_batches(self, batch_size):\n",
    "        self.batched_data = []\n",
    "        self.batched_std = []\n",
    "\n",
    "        total_batches = int(math.ceil(len(self.data) / batch_size))\n",
    "\n",
    "        for batch_idx in range(total_batches):\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = start_idx + batch_size\n",
    "            batch_data = self.data[start_idx:end_idx]\n",
    "\n",
    "            self.batched_data.append(batch_data)\n",
    "            self.batched_std.append(self._compute_batch_std(batch_data))\n",
    "\n",
    "        random.shuffle(self.batched_data)  # Shuffle the batches\n",
    "        random.shuffle(self.batched_std)   # Shuffle the corresponding std deviations\n",
    "\n",
    "        return self.batched_data\n",
    "    \n",
    "    def save_data_as_pickle(self, data, filename):\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(data, file)\n",
    "\n",
    "    def load_from_pickle(self, filename):\n",
    "        with open(filename, 'rb') as file:\n",
    "            self.data = pickle.load(file)\n",
    "        return self.data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of simulations: 22, Number of timesteps: 1001\n",
      "Loading simulation 1/22\n",
      "Loading simulation 2/22\n",
      "Loading simulation 3/22\n",
      "Loading simulation 4/22\n",
      "Loading simulation 5/22\n",
      "Loading simulation 6/22\n",
      "Loading simulation 7/22\n",
      "Loading simulation 8/22\n",
      "Loading simulation 9/22\n",
      "Loading simulation 10/22\n",
      "Loading simulation 11/22\n",
      "Loading simulation 12/22\n",
      "Loading simulation 13/22\n",
      "Loading simulation 14/22\n",
      "Loading simulation 15/22\n",
      "Loading simulation 16/22\n",
      "Loading simulation 17/22\n",
      "Loading simulation 18/22\n",
      "Loading simulation 19/22\n",
      "Loading simulation 20/22\n",
      "Loading simulation 21/22\n",
      "Loading simulation 22/22\n",
      "Loaded simulation 17/22\n",
      "Progress: 77.27%\n",
      "Loaded simulation 12/22\n",
      "Progress: 54.55%\n",
      "Loaded simulation 13/22\n",
      "Progress: 59.09%\n",
      "Loaded simulation 7/22\n",
      "Progress: 31.82%\n",
      "Loaded simulation 5/22\n",
      "Progress: 22.73%\n",
      "Loaded simulation 16/22\n",
      "Progress: 72.73%\n",
      "Loaded simulation 15/22\n",
      "Progress: 68.18%\n",
      "Loaded simulation 11/22\n",
      "Progress: 50.00%\n",
      "Loaded simulation 3/22\n",
      "Progress: 13.64%\n",
      "Loaded simulation 21/22\n",
      "Progress: 95.45%\n",
      "Loaded simulation 8/22\n",
      "Progress: 36.36%\n",
      "Loaded simulation 9/22\n",
      "Progress: 40.91%\n",
      "Loaded simulation 14/22\n",
      "Progress: 63.64%\n",
      "Loaded simulation 2/22\n",
      "Progress: 9.09%\n",
      "Loaded simulation 18/22\n",
      "Progress: 81.82%\n",
      "Loaded simulation 6/22\n",
      "Progress: 27.27%\n",
      "Loaded simulation 4/22\n",
      "Progress: 18.18%\n",
      "Loaded simulation 20/22\n",
      "Progress: 90.91%\n",
      "Loaded simulation 22/22\n",
      "Progress: 100.00%\n",
      "Loaded simulation 19/22\n",
      "Progress: 86.36%\n",
      "Loaded simulation 10/22\n",
      "Progress: 45.45%\n",
      "Loaded simulation 1/22\n",
      "Progress: 4.55%\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader('./simulation_output', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dataloader.save_data_as_pickle(dataloader.data, 'data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
